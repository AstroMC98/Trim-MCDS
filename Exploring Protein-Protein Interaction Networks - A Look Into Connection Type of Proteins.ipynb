{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Python Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statistics import mean,mode,median \n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"all_data_19_07_19.tsv\",delimiter=\"\\t\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trim 1: Extract Relevant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset[['ENTITYA','TYPEA','ENTITYB','TYPEB','MECHANISM','EFFECT','DIRECT']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())\n",
    "print('-------------------------------')\n",
    "print(df['TYPEA'].value_counts())\n",
    "print('-------------------------------')\n",
    "print(df['TYPEB'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We further trim our dataset by limiting our entities to either proteins, complexes, or protein families."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_types = ['protein','complex','proteinfamily']\n",
    "df = df[df['TYPEA'].isin(relevant_types)]\n",
    "df = df[df['TYPEB'].isin(relevant_types)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())\n",
    "print('-------------------------------')\n",
    "print(df['TYPEA'].value_counts())\n",
    "print('-------------------------------')\n",
    "print(df['TYPEB'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We further trim our dataset by limiting our connections to direct connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['DIRECT'] == 'YES']\n",
    "print(df.info())\n",
    "print('-------------------------------')\n",
    "print(df['TYPEA'].value_counts())\n",
    "print('-------------------------------')\n",
    "print(df['TYPEB'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we remove vagueness from EFFECT by removing the all interactions with an unknown effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['EFFECT'] != 'unknown']\n",
    "print(df.info())\n",
    "print('-------------------------------')\n",
    "print(df['EFFECT'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplifying Column Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this study, we will be simplifying our effects column by generalizing the different types to either up-regulating, down-regulating, or complex-forming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EFFECT'].replace(regex={r'(up-regulates).*$': 'up', r'(down-regulates).*$': 'down','form complex':'complex'},inplace = True)\n",
    "df['EFFECT'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Graph via NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graph = df[['ENTITYA','ENTITYB','MECHANISM','EFFECT']]\n",
    "Graph = nx.from_pandas_edgelist(df_graph,'ENTITYA','ENTITYB',edge_attr = ['MECHANISM','EFFECT'], create_using = nx.Graph())\n",
    "G_mech = nx.get_edge_attributes(Graph,'MECHANISM')\n",
    "G_effect = nx.get_edge_attributes(Graph,'EFFECT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Trimming with respect to effect\n",
    "\n",
    "We trim and retain edges within a network with respect to the following condition statements:\n",
    "\n",
    "* The **succeeding/preceeding node** must have the **same type of regulation** as the node of interest, else trim it off **unless** \\\n",
    "* The connection is a **binding mechanism** \\\n",
    "* The **succeeding/preceeding node** is a **complex** \\\n",
    "* **Parameters are easily configured**\n",
    "\n",
    "To initialize our trimming function, we make an initial seed with no nodes and edges that we will grow our trimmed network from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sappling(seed):\n",
    "    G = nx.Graph()\n",
    "    states = {seed:['root']}\n",
    "    edges = set(Graph.edges(seed))\n",
    "    G.add_edges_from(Graph.edges(seed))\n",
    "    for edge in edges:\n",
    "        try:\n",
    "            state = G_effect[edge]\n",
    "            states[edge[0]] = [state]\n",
    "        except KeyError:\n",
    "            edge_inv = tuple([edge[1], edge[0]])\n",
    "            state = G_effect[edge_inv]\n",
    "            states[edge[1]] = [state]\n",
    "            \n",
    "    return G,states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sappling,states = build_sappling('FOXM1')\n",
    "sappling.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_copies(branches):\n",
    "    unique_branches = []\n",
    "    for branch in branches:\n",
    "        branch1 = branch\n",
    "        branch2 = (branch[1],branch[0])\n",
    "        if (branch1 or branch2) not in set (sappling.edges):\n",
    "            unique_branches.append(branch1)\n",
    "    return unique_branches\n",
    "\n",
    "\n",
    "def grow_tree(root,tree_branches,states):\n",
    "    orig_edges = set(root.edges())\n",
    "    time.sleep(1.0)\n",
    "    for branch in tqdm(set(tree_branches)):\n",
    "        bud = branch[1]\n",
    "        try:\n",
    "            bud_state = states[bud]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        potential_branches = remove_copies(set(Graph.edges(bud)))\n",
    "        for pb in potential_branches:\n",
    "            try:\n",
    "                state = G_effect[pb]\n",
    "                mech = G_mech[pb]\n",
    "                node = pb[1]\n",
    "            except KeyError:\n",
    "                pb_inv = (pb[1],pb[0])\n",
    "                state = G_effect[pb_inv]\n",
    "                mech = G_mech[pb_inv]\n",
    "                node = pb[0]\n",
    "            #print(node)\n",
    "            if ((state in bud_state) or ('complex' in bud_state) or ('complex' in state) or (mech == 'binding')):\n",
    "                root.add_edge(pb[0],pb[1])\n",
    "                if node not in states.keys():\n",
    "                    states[node] = [state]\n",
    "                elif node in states.keys():\n",
    "                    states_vals = set(states[node]).union(set([state]))\n",
    "                    states[node] = list(states_vals)\n",
    "    updated_edges = set(root.edges())\n",
    "    edge_diff = len(updated_edges)-len(orig_edges)\n",
    "    new_edges = updated_edges.difference(orig_edges)\n",
    "    time.sleep(1.0)\n",
    "    print('# of new edges:',edge_diff)\n",
    "    #print(new_edges)\n",
    "    return edge_diff,new_edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_diff = 1\n",
    "lvl = 0\n",
    "while edge_diff != 0:\n",
    "    print('-------------')\n",
    "    print(f'@ Level {lvl}:')\n",
    "    if lvl == 0:\n",
    "        edge_diff,new_edges = grow_tree(sappling,sappling.edges(),states)\n",
    "    else:\n",
    "        edge_diff,new_edges = grow_tree(sappling,new_edges,states)\n",
    "    lvl +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original Network Logistics:')\n",
    "print('----------------------------------------')\n",
    "print(f'Total Nodes:{len(Graph.nodes())}')\n",
    "print(f'Total Edges:{len(Graph.edges())}')\n",
    "print('----------------------------------------')\n",
    "print('Trimmed Network Logistics:')\n",
    "print('----------------------------------------')\n",
    "print(f'Total Nodes:{len(sappling.nodes())}')\n",
    "print(f'Total Edges:{len(sappling.edges())}')\n",
    "print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Minimum Leaf Spanning Tree Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undirected Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tree = sappling.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = set(Tree.nodes())\n",
    "v = 'FOXM1'\n",
    "MCDS = set([v])\n",
    "edges = set(Tree.edges(v))\n",
    "W = set()\n",
    "for x in edges:\n",
    "    W.add(x[1])\n",
    "U = set([v]) | W\n",
    "while U != V:\n",
    "    w = None\n",
    "    w_length = 0\n",
    "    for node in W:\n",
    "        nghbr = set(Tree.edges(node))\n",
    "        Gnode = set()\n",
    "        for x in nghbr:\n",
    "            Gnode.add(x[1])\n",
    "        nghbrs = set(Gnode) - U\n",
    "        if len(nghbrs) > w_length:\n",
    "            w_length = len(nghbrs)\n",
    "            w = node\n",
    "    MCDS = MCDS | set([w])\n",
    "    print(MCDS)\n",
    "    neighborhood = set(Tree.edges(w))\n",
    "    edg = set()\n",
    "    for x in neighborhood:\n",
    "        edg.add(x[1])\n",
    "    U = U | edg\n",
    "    W = (W - set([w])) | (edg - set([v]))\n",
    "    v = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(MCDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('FOXM1_path.txt', 'w') as filehandle:\n",
    "    for x in MCDS:\n",
    "        filehandle.writelines(\"%s, \" % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directed Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directedTree = sappling.to_directed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 1 : Treat Directed Graph as Undirected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this version is simply an implementation of the undirected MCDS algorithm and simply configures it for use in the case of a directed graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZATION OF CODE SNIPET\n",
    "V = set(directedTree.nodes()) #Sets V as all nodes\n",
    "# CHOOSE A NODE V WITH HIGHEST DEGREE\n",
    "v = 'FOXM1'\n",
    "MCDS = set([v]) #Outputs Node with most connections\n",
    "inward = set(directedTree.in_edges(v))\n",
    "outward = set(directedTree.out_edges(v))\n",
    "W = set()\n",
    "for x in inward:\n",
    "    W.add(x[0])\n",
    "for y in outward:\n",
    "    W.add(y[1])\n",
    "#W = set(directedTree[v]) #Saves Nodes which are connected to node with most connections\n",
    "U = set([v]) | W\n",
    "while U != V:\n",
    "    w = None\n",
    "    w_length = 0\n",
    "    for node in W:\n",
    "        inward2 = set(directedTree.in_edges(node))\n",
    "        outward2 = set(directedTree.out_edges(node))\n",
    "        Gnode = set()\n",
    "        for x in inward2:\n",
    "              Gnode.add(x[0])\n",
    "        for y in outward2:\n",
    "              Gnode.add(y[1])\n",
    "        neighbours = set(Gnode) - U\n",
    "        if (len(neighbours) > w_length):\n",
    "            w_length = len(neighbours)\n",
    "            w = node\n",
    "    MCDS = MCDS | set([w])\n",
    "    print(MCDS)\n",
    "    inward3 = set(directedTree.in_edges(w))\n",
    "    outward3 = set(directedTree.out_edges(w))\n",
    "    edi = set()\n",
    "    for x in inward3:\n",
    "        edi.add(x[0])\n",
    "    for y in outward3:\n",
    "        edi.add(y[1])\n",
    "    U = U | edi\n",
    "    W = (W - set([w])) | (edi - set([v]))\n",
    "    v = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(MCDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('FOXM1_path_directedv1.txt', 'w') as filehandle:\n",
    "    for x in MCDS:\n",
    "        filehandle.writelines(\"%s, \" % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2: Directed Graph Implementation inspired from MLST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
